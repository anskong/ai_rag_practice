{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2a0cab0",
   "metadata": {},
   "source": [
    "## **RAG의 핵심, 문서 검색기 Retriever**\n",
    "### **사용자의 쿼리를 재해석하여 검색하다, MultiQueryRetriever**\n",
    "**Chroma DB에 문서 벡터 저장**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310a4728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경변수 읽어오기\n",
    "load_dotenv(override=True)  # .env 파일을 덮어쓰기 모드로 읽기\n",
    "\n",
    "# 환경변수 불러오기\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "anthropic_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "huggingface_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "print(f\"openai key values ::: {openai_key}\")  # 테스트용 (실제 서비스에서는 print 금지)\n",
    "print(f\"anthropic key values ::: {anthropic_key}\")  # 테스트용 (실제 서비스에서는 print 금지)\n",
    "print(f\"huggingface_token::: {huggingface_token}\")  # 테스트용 (실제 서비스에서는 print 금지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684e9f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "result = embedding_model.embed_query(\"테스트 문장입니다.\")\n",
    "print(result[:5])  #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e738e4b",
   "metadata": {},
   "source": [
    "Test 소스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599490ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "# from langchain_community.vectorstores import Chroma\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "#헌법 PDF 파일 로드\n",
    "\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - window11 \n",
    "loader = PyPDFLoader(r\"G:\\내 드라이브\\LLM-RAG-LangChain\\대한민국헌법(헌법제1호).pdf\")\n",
    "\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - macOS\n",
    "# loader = PyPDFLoader(\n",
    "#     r\"/Users/youngho_moon/Library/CloudStorage/GoogleDrive-anskong@gmail.com/내 드라이브/LLM-RAG-LangChain/대한민국헌법(헌법)(제00010호)(19880225).pdf\"\n",
    "# )\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "#PDF 파일을 500자 청크로 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "# docs = text_splitter.split_documents(pages)\n",
    "\n",
    "# Chroma를 제거하고 임베딩만 추출\n",
    "docs = text_splitter.split_documents(pages[:3])  # 소량만 사용\n",
    "\n",
    "# 임베딩 결과 확인\n",
    "embedding_model = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "for doc in docs:\n",
    "    vec = embedding_model.embed_query(doc.page_content)\n",
    "    print(vec[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c738c531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings                           \n",
    "from langchain_community.vectorstores import Chroma\n",
    "# from langchain_chroma import Chroma\n",
    "\n",
    "import shutil\n",
    "\n",
    "import logging\n",
    "\n",
    "# 기본 로깅 설정\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# ChromaDB 관련 로거 활성화\n",
    "# logging.getLogger(\"chromadb\").setLevel(logging.DEBUG)\n",
    "# logging.getLogger(\"chromadb.db\").setLevel(logging.DEBUG)\n",
    "# logging.getLogger(\"chromadb.telemetry\").setLevel(logging.INFO)\n",
    "\n",
    "#헌법 PDF 파일 로드\n",
    "\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - window11 \n",
    "# loader = PyPDFLoader(r\"G:\\내 드라이브\\LLM-RAG-LangChain\\대한민국헌법(헌법제1호).pdf\")\n",
    "\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - macOS\n",
    "loader = PyPDFLoader(\n",
    "    r\"/Users/youngho_moon/Library/CloudStorage/GoogleDrive-anskong@gmail.com/내 드라이브/LLM-RAG-LangChain/대한민국헌법(헌법)(제00010호)(19880225).pdf\"\n",
    ")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "#PDF 파일을 500자 청크로 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages[:5])\n",
    "\n",
    "#ChromaDB에 청크들을 벡터 임베딩으로 저장(OpenAI 임베딩 모델 활용)\n",
    "# db = Chroma.from_documents(docs, OpenAIEmbeddings(model = 'text-embedding-3-small'))\n",
    "# db = Chroma.from_documents(\n",
    "#     docs,\n",
    "#     OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    "#     persist_directory=\"./chroma_db\"  # 폴더 직접 지정\n",
    "# )\n",
    "\n",
    "# shutil.rmtree(\"C:/temp/chroma_db\", ignore_errors=True)\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "\n",
    "# shutil.rmtree(\"./chroma_db\", ignore_errors=True)\n",
    "db = Chroma.from_documents(docs, embedding_model, persist_directory=\"./chroma_db\")\n",
    "\n",
    "# db = Chroma(\n",
    "#     embedding_function=embedding_model,\n",
    "#     persist_directory=\"C:/temp/chroma_db\",\n",
    "#     collection_name=\"my_collection\"\n",
    "# )\n",
    "\n",
    "# # 소규모 배치로 나누어 삽입\n",
    "# batch_size = 5\n",
    "# for i in range(0, len(docs), batch_size):\n",
    "#     batch = docs[i:i + batch_size]\n",
    "#     db.add_documents(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2b9c67",
   "metadata": {},
   "source": [
    "**질문을 여러 버전으로 재해석하여 Retriever에 활용**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5468b900",
   "metadata": {},
   "outputs": [],
   "source": [
    "#```Chroma DB에 대한민국 헌법 PDF 임베딩 변환 및 저장하는 과정은 위 셀에 있습니다```\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#질문 문장 question으로 저장\n",
    "question = \"국회의원의 의무는 무엇이 있나요?\"\n",
    "#여러 버전의 질문으로 변환하는 역할을 맡을 LLM 선언\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\",\n",
    "                 temperature = 0)\n",
    "#MultiQueryRetriever에 벡터DB 기반 Retriever와 LLM 선언\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=db.as_retriever(), llm=llm\n",
    ")\n",
    "\n",
    "# 여러 버전의 문장 생성 결과를 확인하기 위한 로깅 과정\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n",
    "\n",
    "#여러 버전 질문 생성 결과와 유사 청크 검색 개수 출력\n",
    "unique_docs = retriever_from_llm.invoke(input=question)\n",
    "len(unique_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aa2a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759a2c88",
   "metadata": {},
   "source": [
    "### **<span style=\"color:yellow\">재정렬 기법(Reorder or Rerank)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1b6068",
   "metadata": {},
   "source": [
    "**[Long-Context Reorder 없이 유사 문서 출력]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bafe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chroma dimension 관련 에러 발생 시 실행\n",
    "# Chroma().delete_collection()\n",
    "\n",
    "# pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e40e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.document_transformers import (\n",
    "    LongContextReorder,\n",
    ")\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "texts = [\n",
    "    \"바스켓볼은 훌륭한 스포츠입니다.\",\n",
    "    \"플라이 미 투 더 문은 제가 가장 좋아하는 노래 중 하나입니다.\",\n",
    "    \"셀틱스는 제가 가장 좋아하는 팀입니다.\",\n",
    "    \"이것은 보스턴 셀틱스에 관한 문서입니다.\"\n",
    "    \"저는 단순히 영화 보러 가는 것을 좋아합니다\",\n",
    "    \"보스턴 셀틱스가 20점차로 이겼어요\",\n",
    "    \"이것은 그냥 임의의 텍스트입니다.\",\n",
    "    \"엘든 링은 지난 15 년 동안 최고의 게임 중 하나입니다.\",\n",
    "    \"L. 코넷은 최고의 셀틱스 선수 중 한 명입니다.\",\n",
    "    \"래리 버드는 상징적인 NBA 선수였습니다.\",\n",
    "]\n",
    "# Chroma Retriever 선언(10개의 유사 문서 출력)\n",
    "retriever = FAISS.from_texts(texts, OpenAIEmbeddings(model = 'text-embedding-3-small')).as_retriever(\n",
    "    search_kwargs={\"k\": 10}\n",
    ")\n",
    "query = \"셀틱에 대해 설명해줘\"\n",
    "\n",
    "# 유사도 기준으로 검색 결과 출력\n",
    "docs = retriever.invoke(query)\n",
    "for i in docs:\n",
    "  print(i.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94605217",
   "metadata": {},
   "source": [
    "**[Long-Context Reorder 활용하여 유사 문서 출력]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3de8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_transformers import (\n",
    "    LongContextReorder,\n",
    ")\n",
    "#LongContextReorder 선언\n",
    "reordering = LongContextReorder()\n",
    "#검색된 유사문서 중 관련도가 높은 문서를 맨앞과 맨뒤에 재정배치\n",
    "reordered_docs = reordering.transform_documents(docs)\n",
    "for i in reordered_docs:\n",
    "  print(i.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ef4ae4",
   "metadata": {},
   "source": [
    "**필요없는 문서는 삭제, Contextual Compression, 맥락 압축 기법(Context Compression)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770d43de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for printing docs\n",
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c23c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Helper function for printing docs\n",
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )\n",
    "\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - macOS\n",
    "loader = PyPDFLoader(\n",
    "    r\"/Users/youngho_moon/Library/CloudStorage/GoogleDrive-anskong@gmail.com/내 드라이브/LLM-RAG-LangChain/대한민국헌법(헌법)(제00010호)(19880225).pdf\"\n",
    ")\n",
    "pages = loader.load_and_split()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages)\n",
    "db = FAISS.from_documents(docs, OpenAIEmbeddings(model = 'text-embedding-3-small'))\n",
    "retriever =db.as_retriever()\n",
    "\n",
    "docs = retriever.invoke(\"대통령의 임기는?\") \n",
    "pretty_print_docs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0238bcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model ='gpt-4o-mini', temperature=0)\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")\n",
    "\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    \"대통령의 임기는?\"\n",
    ")\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005e0bc8",
   "metadata": {},
   "source": [
    "### **<span style=\"color:yellow\">가상 문서로 유사 문서 탐색, HyDE(Hypothetical Document Embedding)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc1851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "system = \"\"\"\n",
    "당신은 LangChain, LangGraph, LangServe, LangSmith라는 LLM 기반 애플리케이션을 구축하기 위한 일련의 소프트웨어에 대한 전문가입니다.\n",
    "\n",
    "LangChain은 LLM 애플리케이션을 구축하기 위해 쉽게 구성할 수 있는 대규모 통합 세트를 제공하는 Python 프레임워크입니다.\n",
    "LangGraph는 상태 저장, 멀티 액터 LLM 애플리케이션을 쉽게 구축할 수 있는 LangChain 위에 구축된 Python 패키지입니다.\n",
    "LangServe는 REST API로 LangChain 애플리케이션을 쉽게 배포할 수 있는 LangChain 위에 구축된 Python 패키지입니다.\n",
    "LangSmith는 LLM 애플리케이션 추적 및 테스트를 쉽게 할 수 있는 플랫폼입니다.\n",
    "\n",
    "사용자 질문에 최선을 다해 답변하세요. 사용자 질문에 대한 튜토리얼을 작성하는 것처럼 답변하세요.\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "qa_no_context = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e46d189",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = qa_no_context.invoke(\n",
    "    {\n",
    "        \"question\": \"Chain을 구축할 때 멀티모달 모델을 활용하는 방법과 Chain을 REST API로 전환하는 방법\"\n",
    "    }\n",
    ")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b5897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "hyde_chain = RunnablePassthrough.assign(hypothetical_document=qa_no_context)\n",
    "\n",
    "hyde_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"Chain을 구축할 때 멀티모달 모델을 활용하는 방법과 Chain을 REST API로 전환하는 방법\"\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yhmoon05",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
