{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "970fbe07",
   "metadata": {},
   "source": [
    "**LLM - chatGPT, Anthropic** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfd496b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai key values ::: 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\n",
      "anthropic key values ::: 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\n",
      "huggingface_token::: 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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경변수 읽어오기\n",
    "load_dotenv(override=True)  # .env 파일을 덮어쓰기 모드로 읽기\n",
    "\n",
    "# 환경변수 불러오기\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "anthropic_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "huggingface_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "print(f\"openai key values ::: {openai_key}\")  # 테스트용 (실제 서비스에서는 print 금지)\n",
    "print(f\"anthropic key values ::: {anthropic_key}\")  # 테스트용 (실제 서비스에서는 print 금지)\n",
    "print(f\"huggingface_token::: {huggingface_token}\")  # 테스트용 (실제 서비스에서는 print 금지)\n",
    "#...ddd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3194f0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from anthropic import Anthropic\n",
    "import httpx  \n",
    "\n",
    "vfy_client = httpx.Client(verify=False)\n",
    "\n",
    "# 1. 직접 Anthropic\n",
    "client = Anthropic(api_key=anthropic_key, http_client=vfy_client)\n",
    "\n",
    "# 2. Langchain Anthropic 모델 호출\n",
    "chat = ChatAnthropic(\n",
    "    model_name =\"claude-3-opus-20240229\",\n",
    "    anthropic_api_key=anthropic_key,)\n",
    "\n",
    "chat._client = client\n",
    "\n",
    "# chat._client._transport._pool._ssl_context.check_hostname = False\n",
    "# chat._client._transport._pool._ssl_context.verify_mode = 0  # ssl.CERT_NONE\n",
    "chat.invoke(\"안녕~ 너를 소개해줄래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716129a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "import httpx    \n",
    "\n",
    "\n",
    "\n",
    "print(f\"anthropic key values ::: {anthropic_key}\")\n",
    "\n",
    "vfy_client = httpx.Client(verify=False)\n",
    "\n",
    "client = anthropic.Anthropic(api_key=anthropic_key, http_client=vfy_client)\n",
    "\n",
    "\n",
    "# client._client._transport._pool._ssl_context.check_hostname = False\n",
    "# client._client._transport._pool._ssl_context.verify_mode = 0  # ssl.CERT_NONE\n",
    "\n",
    "# print(\"client values {} ::: {}\".format(type(client), client) ) # 테스트용 (실제 서비스에서는 print 금지)\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=\"claude-3-opus-20240229\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Anthropic AI 소개해줘\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a413a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 저는 AI 언어 모델인 OpenAI의 챗봇입니다. 사람들과 자연스러운 대화를 나누기 위해 개발되었으며, 다양한 주제에 대해 정보를 제공하고 질문에 답변할 수 있습니다. 학습된 데이터를 바탕으로 대화를 이해하고 응답을 생성하며, 지속적으로 발전하고 있습니다. 도움이 필요하시면 언제든지 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model_name = 'gpt-4o',\n",
    "    openai_api_key=openai_key,\n",
    ")\n",
    "\n",
    "response = chat.invoke(\"너를 소개해줘\")\n",
    "\n",
    "print(response.content)  # 테스트용 (실제 서비스에서는 print 금지)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72b62b1",
   "metadata": {},
   "source": [
    "# **Document Loader**\n",
    "## ***<span style=\"color:yellow\">PDF Loader</span>***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea700c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyPDF 설치\n",
    "# !pip install -q pypdf\n",
    "# G:\\내 드라이브\\문영호\\109 RFP MOH eng.pdf\n",
    "\n",
    "#PyPDFLoader 불러오기\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - window11 \n",
    "# loader = PyPDFLoader(r\"G:\\내 드라이브\\문영호\\109 RFP MOH eng.pdf\")\n",
    "loader = PyPDFLoader(\n",
    "    r\"G:\\내 드라이브\\LLM-RAG-LangChain\\대한민국헌법(헌법)(제00010호)(19880225).pdf\"\n",
    ")\n",
    "\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - macOS\n",
    "# loader = PyPDFLoader(\n",
    "#     r\"/Users/youngho_moon/Library/CloudStorage/GoogleDrive-anskong@gmail.com/내 드라이브/LLM-RAG-LangChain/대한민국헌법(헌법)(제00010호)(19880225).pdf\"\n",
    "# )\n",
    "\n",
    "# PDF파일 로드 및 페이지별로 자르기\n",
    "pages = loader.load_and_split()\n",
    "print(f\"페이지 수: {len(pages)}\")\n",
    "# print(pages[0].page_content)\n",
    "\n",
    "for i in range(5):   \n",
    "    print(f\"페이지 {i+1} 내용\") \n",
    "    print(\"===================================\")\n",
    "    print(pages[i].page_content)\n",
    "    print(pages[i].metadata)\n",
    "    print(pages[i].metadata['page'])\n",
    "    print(pages[i].metadata['page_label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422de17c",
   "metadata": {},
   "source": [
    "# **Text Splitter**\n",
    "\n",
    "<!-- **굵게 (bold)**  \n",
    "*기울임 (italic)*  \n",
    "***굵고 기울임*** -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127676bf",
   "metadata": {},
   "source": [
    "# ***<sapn style=\"color:green\">Text Embbeding</span>***\n",
    "<!-- ## ***글자 크기 조정 2***\n",
    "###  **글자 크기 조정 3** -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409985e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(model = 'text-embedding-3-small')\n",
    "embeddings = embeddings_model.embed_documents(\n",
    "    [\n",
    "        \"Hi there!\",\n",
    "        \"Oh, hello!\",\n",
    "        \"What's your name?\",\n",
    "        \"My friends call me World\",\n",
    "        \"Hello World!\"\n",
    "    ]\n",
    ")\n",
    "len(embeddings), len(embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4c8c9f",
   "metadata": {},
   "source": [
    "## **openAI Embedding Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3dec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFium2Loader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "#임베딩 모델 API 호출\n",
    "embeddings_model = OpenAIEmbeddings(model = 'text-embedding-3-small')\n",
    "\n",
    "#PDF 문서 로드\n",
    "# loader = PyPDFium2Loader(r\"G:\\내 드라이브\\문영호\\109 RFP MOH eng.pdf\")\n",
    "# loader = PyPDFium2Loader(r\"G:\\내 드라이브\\문영호\\알파고\\alphago.pdf\")\n",
    "# loader = PyPDFium2Loader(r\"G:\\내 드라이브\\LLM-RAG-LangChain\\대한민국헌법(헌법)(제00010호)(19880225).pdf\")\n",
    "loader = PyPDFium2Loader(\n",
    "    # r\"/Users/youngho_moon/Library/CloudStorage/GoogleDrive-anskong@gmail.com/내 드라이브/LLM-RAG-LangChain/대한민국헌법(헌법)(제00010호)(19880225).pdf\"\n",
    "    # r\"C:\\Users\\MOON YOUNGHO\\Downloads\\제안요청서_바레인.pdf\"\n",
    "    r\"G:\\내 드라이브\\LLM-RAG-LangChain\\제안요청서_바레인.pdf\"\n",
    ")\n",
    "# PDF파일 로드 및 페이지별로 자르기\n",
    "pages = loader.load()\n",
    "\n",
    "#PDF 문서를 여러 청크로 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "\n",
    "#청크 수 확인\n",
    "print(f\"청크 수: {len(chunks)}\")\n",
    "#청크 내용 확인\n",
    "print(\"started printing chunk contents\")\n",
    "for i in range(233,244):   \n",
    "    print(f\"청크 {i+1} 내용\") \n",
    "    print(\"===================================\")\n",
    "    print(chunks[i].page_content)\n",
    "    print(chunks[i].metadata)\n",
    "    print(chunks[i].metadata['page'])\n",
    "    # print(texts[i].metadata['page_label'])\n",
    "print(\"finished printing chunk contents\")\n",
    "\n",
    "#OpenAI 임베딩 모델로 청크들을 임베딩 변환하기\n",
    "embeddings = embeddings_model.embed_documents([i.page_content for i in chunks])\n",
    "len(embeddings), len(embeddings[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d9eb64",
   "metadata": {},
   "source": [
    "##### **[문장 유사도]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2dc6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = [\n",
    "        \"안녕하세요\",\n",
    "        \"제 이름은 홍두깨입니다.\",\n",
    "        \"AI 초보자로서 잘 부탁드립니다.\",\n",
    "        \"열심히 배워서 회사의 발전에 이바지할 수 있는 인재로 성장하겠습니다.\",\n",
    "        \"LG CNS 만세 저는 아부쟁이입니다.\"\n",
    "    ]\n",
    "embeddings = embeddings_model.embed_documents(chunk)\n",
    "print(embeddings)\n",
    "\n",
    "# 임베딩 모델 API 호출 - embed_query\n",
    "embedded_query_q1 = embeddings_model.embed_query(\"이 대화에서 언급된 이름은 무엇입니까?\")\n",
    "embedded_query_q2 = embeddings_model.embed_query(\"이 대화에서 언급된 사람의 포부는 무엇입니까?\")\n",
    "embedded_query_q3 = embeddings_model.embed_query(\"이 대화에서 언급된 사람은 아부쟁이일까요 아닐까요?\")\n",
    "embedded_query_a = embeddings_model.embed_query(\"이 대화에서 언급된 이름은 홍길동입니다.\")\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "\n",
    "# 임베딩 간 유사도 함수\n",
    "def cos_sim(A, B):\n",
    "       return dot(A, B)/(norm(A)*norm(B))\n",
    "\n",
    "for i in range(len(embeddings)):\n",
    "    print(chunk[i])\n",
    "    print(cos_sim(embedded_query_q3, embeddings[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df37847a",
   "metadata": {},
   "source": [
    "### **오픈소스 임베딩 모델 활용하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2d29b9",
   "metadata": {},
   "source": [
    "**[jhgan/ko-sroberta-multitask 임베딩 모델 활용]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4d8649e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0121b4024104a84980e66fb4385717c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70af3e618fe4c19a49a33899f107151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/585 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25abcd1b2fe84935899ab55bfee5f0aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56baacb61fdd4b56b1bb00d2d64bc4ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da5bcbafb154023977e839625307dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/442M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed94a313a754036b22f4f00da0b2fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b489276c4f407facbcffad232bc083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6070004964243924\n",
      "0.2947341114437129\n",
      "0.2757840135946338\n"
     ]
    }
   ],
   "source": [
    "# pip install sentence-transformers\n",
    "# pip install --upgrade sentence-transformers  ->  필요\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "\n",
    "# 임베딩 간 유사도 함수\n",
    "def cos_sim(A, B):\n",
    "       return dot(A, B)/(norm(A)*norm(B))\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "#HuggingfaceEmbedding 함수로 Open source 임베딩 모델 로드\n",
    "model_name = \"jhgan/ko-sroberta-multitask\"\n",
    "# 한국어 NLI 기반 SBERT, RAG용으로 최적화된 모델\n",
    "# model_name = \"jhgan/ko-sbert-nli\"\n",
    "ko_embedding= HuggingFaceEmbeddings(\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "examples = ko_embedding.embed_documents(\n",
    "     [\n",
    "        \"안녕하세요\",\n",
    "        \"제 이름은 홍두깨입니다.\",\n",
    "        \"이름이 무엇인가요?\",\n",
    "        \"랭체인은 유용합니다.\",\n",
    "     ]\n",
    " )\n",
    "\n",
    "embedded_query_q = ko_embedding.embed_query(\"이 대화에서 언급된 이름은 무엇입니까?\")\n",
    "embedded_query_a = ko_embedding.embed_query(\"이 대화에서 언급된 이름은 홍길동입니다.\")\n",
    "\n",
    "print(cos_sim(embedded_query_q, embedded_query_a))\n",
    "print(cos_sim(embedded_query_q, examples[1]))\n",
    "print(cos_sim(embedded_query_q, examples[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e4c4d4",
   "metadata": {},
   "source": [
    "**[BAAI/bge-small-en 임베딩 모델 활용 코드]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67608f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "bge_embedding= HuggingFaceEmbeddings(\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "examples = bge_embedding.embed_documents(\n",
    "     [\n",
    "        \"안녕하세요\",\n",
    "        \"제 이름은 홍두깨입니다.\",\n",
    "        \"이름이 무엇인가요?\",\n",
    "        \"랭체인은 유용합니다.\",\n",
    "     ]\n",
    " )\n",
    "\n",
    "embedded_query_q = bge_embedding.embed_query(\"이 대화에서 언급된 이름은 무엇입니까?\")\n",
    "embedded_query_a = bge_embedding.embed_query(\"이 대화에서 언급된 이름은 홍길동입니다.\")\n",
    "\n",
    "print(cos_sim(embedded_query_q, embedded_query_a))\n",
    "print(cos_sim(embedded_query_q, examples[1]))\n",
    "print(cos_sim(embedded_query_q, examples[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2586ae4f",
   "metadata": {},
   "source": [
    "## **문서 벡터 저장소, Vector Stores**\n",
    "### **Langchain-Chroma 문서 저장 및 유사 문서 검색**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452e27ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "openai_embedding=OpenAIEmbeddings(model = 'text-embedding-3-small')\n",
    "\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - window11 \n",
    "# loader = PyPDFLoader(r\"G:\\내 드라이브\\문영호\\109 RFP MOH eng.pdf\")\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - macOS\n",
    "loader = PyPDFLoader(\n",
    "    r\"/Users/youngho_moon/Library/CloudStorage/GoogleDrive-anskong@gmail.com/내 드라이브/LLM-RAG-LangChain/대한민국헌법(헌법)(제00010호)(19880225).pdf\"\n",
    ")\n",
    "\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "db = Chroma.from_documents(docs, openai_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c931aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"대통령의 임기는?\"\n",
    "#유사 문서 검색\n",
    "docs = db.similarity_search(query)\n",
    "for doc in docs:\n",
    "    print(\"===================================\")\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)\n",
    "    print(doc.metadata['page'])\n",
    "    # print(doc.metadata['page_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f601860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#유사 문서 검색 및 유사도 출력\n",
    "db.similarity_search_with_score(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e85f78",
   "metadata": {},
   "source": [
    "**<span style='color:green'>[벡터DB를 로컬 디스크에 저장하고 로드하기]</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c1f9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Chroma().delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8ac890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - macOS\n",
    "loader = PyPDFLoader(\n",
    "    r\"/Users/youngho_moon/Library/CloudStorage/GoogleDrive-anskong@gmail.com/내 드라이브/LLM-RAG-LangChain/대한민국헌법(헌법)(제00010호)(19880225).pdf\"\n",
    ")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "\n",
    "#HuggingfaceEmbedding 함수로 Open source 임베딩 모델 로드\n",
    "model_name = \"jhgan/ko-sroberta-multitask\"\n",
    "ko_embedding= HuggingFaceEmbeddings(\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "#save to local disk,\n",
    "db2 = Chroma.from_documents(docs, ko_embedding, persist_directory=\"./chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42381e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from disk\n",
    "db3 = Chroma(persist_directory=\"./chroma_db\", embedding_function=ko_embedding)\n",
    "\n",
    "query = \"대통령의 임기는?\"\n",
    "result = db3.similarity_search(query)\n",
    "print(result[0].page_content)\n",
    "\n",
    "# # load from disk\n",
    "# db3 = Chroma(persist_directory=\"./chroma_db\", embedding_function=ko_embedding)\n",
    "\n",
    "# query = \"대통령의 임기는?\"\n",
    "# result = db3.similarity_search(query)\n",
    "# print(result[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffeace1",
   "metadata": {},
   "source": [
    "## **RAG의 핵심, 문서 검색기 Retriever**\n",
    "### **Retriever의 기본형, 벡터DB 기반 Retriever**\n",
    "**<span style='color:yellow'>Chroma 벡터 DB 기반 기본 유사 문서 검색</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aa85ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "#헌법 PDF 파일 로드\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - macOS\n",
    "loader = PyPDFLoader(\n",
    "    r\"/Users/youngho_moon/Library/CloudStorage/GoogleDrive-anskong@gmail.com/내 드라이브/LLM-RAG-LangChain/대한민국헌법(헌법)(제00010호)(19880225).pdf\"\n",
    ")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "#PDF 파일을 500자 청크로 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "#ChromaDB에 청크들을 벡터 임베딩으로 저장(OpenAI 임베딩 모델 활용)\n",
    "db = Chroma.from_documents(docs, OpenAIEmbeddings(model = 'text-embedding-3-small'))\n",
    "\n",
    "#Chroma를 Retriever로 활용\n",
    "retriever = db.as_retriever()\n",
    "retriever.invoke(\"국회의원의 의무\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3ecd68",
   "metadata": {},
   "source": [
    "**(1) 검색 결과 수 및 조정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e84dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#유사 청크 1개만 반환\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 10})\n",
    "retriever.invoke(\"국회의원의 의무\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db2b754",
   "metadata": {},
   "source": [
    "**(2) 검색 방식 변경 - MMR**\n",
    "\n",
    "MMR은 쿼리에 대한 (1) 각 문서의 유사성 점수와 (2) 이미 선택된 문서들과의 다양성점수를 조합하여, 각 문서의 최종 점수를 계산합니다.\n",
    "\n",
    "$\\text{MMR} = \\lambda \\cdot \\text{Sim}(d, Q) - (1 - \\lambda) \\cdot \\max_{d' \\in D'} \\text{Sim}(d, d')$\n",
    "\n",
    "즉 유사 문서 후보군 중 특정 문서가 후보군 내 문서들 간의 유사성은 낮고, 쿼리와의 유사성이 높은 경우 점수가 높습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e58ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "#헌법 PDF 파일 로드\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - macOS\n",
    "loader = PyPDFLoader(\n",
    "    r\"/Users/youngho_moon/Library/CloudStorage/GoogleDrive-anskong@gmail.com/내 드라이브/LLM-RAG-LangChain/대한민국헌법(헌법)(제00010호)(19880225).pdf\"\n",
    ")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "#PDF 파일을 500자 청크로 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "#ChromaDB에 청크들을 벡터 임베딩으로 저장(OpenAI 임베딩 모델 활용)\n",
    "db = Chroma.from_documents(docs, OpenAIEmbeddings(model = 'text-embedding-3-small'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d011ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chroma를 Retriever로 활용\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs = {\"lambda_mult\": 0, \"fetch_k\":10, \"k\":3}\n",
    ")\n",
    "result = retriever.invoke(\"국회의원의 의무\")\n",
    "for idx, value in enumerate(result):\n",
    "  print(f\"{idx+1}번째 유사 문서:\")\n",
    "  print(value.page_content[:100])\n",
    "  print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa09ae9",
   "metadata": {},
   "source": [
    "**<span style='color:yellow'>일반 유사도 검색 방식**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3defda85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chroma를 Retriever로 활용\n",
    "retriever = db.as_retriever(search_kwargs = {\"k\":3})\n",
    "result = retriever.invoke(\"국회의원의 의무\")\n",
    "for idx, value in enumerate(result):\n",
    "  print(f\"{idx+1}번째 유사 문서:\")\n",
    "  print(value.page_content[:100])\n",
    "  print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
