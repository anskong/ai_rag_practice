{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "970fbe07",
   "metadata": {},
   "source": [
    "LLM - chatGPT, Anthropic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd496b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경변수 읽어오기\n",
    "load_dotenv(override=True)  # .env 파일을 덮어쓰기 모드로 읽기\n",
    "\n",
    "# 환경변수 불러오기\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "anthropic_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "huggingface_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "print(f\"openai key values ::: {openai_key}\")  # 테스트용 (실제 서비스에서는 print 금지)\n",
    "print(f\"anthropic key values ::: {anthropic_key}\")  # 테스트용 (실제 서비스에서는 print 금지)\n",
    "print(f\"huggingface_token::: {huggingface_token}\")  # 테스트용 (실제 서비스에서는 print 금지)\n",
    "#...ddd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "716129a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anthropic key values ::: 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\n",
      "client values <class 'anthropic.Anthropic'> ::: <anthropic.Anthropic object at 0x00000167560578D0>\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'type': 'error', 'error': {'type': 'authentication_error', 'message': 'invalid x-api-key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     13\u001b[39m client._client._transport._pool._ssl_context.verify_mode = \u001b[32m0\u001b[39m  \u001b[38;5;66;03m# ssl.CERT_NONE\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mclient values \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m ::: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mtype\u001b[39m(client), client) ) \u001b[38;5;66;03m# 테스트용 (실제 서비스에서는 print 금지)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclaude-3-opus-20240229\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAnthropic AI 소개해줘\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MOON YOUNGHO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anthropic\\_utils\\_utils.py:283\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    281\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MOON YOUNGHO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anthropic\\resources\\messages\\messages.py:954\u001b[39m, in \u001b[36mMessages.create\u001b[39m\u001b[34m(self, max_tokens, messages, model, metadata, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    947\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m DEPRECATED_MODELS:\n\u001b[32m    948\u001b[39m     warnings.warn(\n\u001b[32m    949\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is deprecated and will reach end-of-life on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEPRECATED_MODELS[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    950\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m    951\u001b[39m         stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m    952\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m954\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/v1/messages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop_sequences\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthinking\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mthinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_k\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsStreaming\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRawMessageStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MOON YOUNGHO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anthropic\\_base_client.py:1290\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1276\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1277\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1278\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1285\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1286\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1287\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1288\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1289\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1290\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MOON YOUNGHO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anthropic\\_base_client.py:1085\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1082\u001b[39m             err.response.read()\n\u001b[32m   1084\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1085\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1087\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1089\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'type': 'error', 'error': {'type': 'authentication_error', 'message': 'invalid x-api-key'}}"
     ]
    }
   ],
   "source": [
    "import anthropic\n",
    "import httpx    \n",
    "\n",
    "\n",
    "\n",
    "print(f\"anthropic key values ::: {anthropic_key}\")\n",
    "\n",
    "client = anthropic.Anthropic(api_key=anthropic_key)\n",
    "\n",
    "httpx.Client(verify=False)\n",
    "\n",
    "client._client._transport._pool._ssl_context.check_hostname = False\n",
    "client._client._transport._pool._ssl_context.verify_mode = 0  # ssl.CERT_NONE\n",
    "\n",
    "print(\"client values {} ::: {}\".format(type(client), client) ) # 테스트용 (실제 서비스에서는 print 금지)\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=\"claude-3-opus-20240229\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Anthropic AI 소개해줘\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a413a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model_name = 'gpt-4o',\n",
    "    openai_api_key=openai_key\n",
    ")\n",
    "response = chat.invoke(\"너를 소개해줘\")\n",
    "\n",
    "print(response.content)  # 테스트용 (실제 서비스에서는 print 금지)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72b62b1",
   "metadata": {},
   "source": [
    "# **Document Loader**\n",
    "## ***<span style=\"color:yellow\">PDF Loader</span>***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea700c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyPDF 설치\n",
    "# !pip install -q pypdf\n",
    "# G:\\내 드라이브\\문영호\\109 RFP MOH eng.pdf\n",
    "\n",
    "#PyPDFLoader 불러오기\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - window11 \n",
    "# loader = PyPDFLoader(r\"G:\\내 드라이브\\문영호\\109 RFP MOH eng.pdf\")\n",
    "loader = PyPDFLoader(\n",
    "    r\"G:\\내 드라이브\\LLM-RAG-LangChain\\대한민국헌법(헌법)(제00010호)(19880225).pdf\"\n",
    ")\n",
    "\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - macOS\n",
    "# loader = PyPDFLoader(\n",
    "#     r\"/Users/youngho_moon/Library/CloudStorage/GoogleDrive-anskong@gmail.com/내 드라이브/LLM-RAG-LangChain/대한민국헌법(헌법)(제00010호)(19880225).pdf\"\n",
    "# )\n",
    "\n",
    "# PDF파일 로드 및 페이지별로 자르기\n",
    "pages = loader.load_and_split()\n",
    "print(f\"페이지 수: {len(pages)}\")\n",
    "# print(pages[0].page_content)\n",
    "\n",
    "for i in range(5):   \n",
    "    print(f\"페이지 {i+1} 내용\") \n",
    "    print(\"===================================\")\n",
    "    print(pages[i].page_content)\n",
    "    print(pages[i].metadata)\n",
    "    print(pages[i].metadata['page'])\n",
    "    print(pages[i].metadata['page_label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422de17c",
   "metadata": {},
   "source": [
    "# **Text Splitter**\n",
    "\n",
    "<!-- **굵게 (bold)**  \n",
    "*기울임 (italic)*  \n",
    "***굵고 기울임*** -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127676bf",
   "metadata": {},
   "source": [
    "# ***<sapn style=\"color:green\">Text Embbeding</span>***\n",
    "<!-- ## ***글자 크기 조정 2***\n",
    "###  **글자 크기 조정 3** -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409985e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(model = 'text-embedding-3-small')\n",
    "embeddings = embeddings_model.embed_documents(\n",
    "    [\n",
    "        \"Hi there!\",\n",
    "        \"Oh, hello!\",\n",
    "        \"What's your name?\",\n",
    "        \"My friends call me World\",\n",
    "        \"Hello World!\"\n",
    "    ]\n",
    ")\n",
    "len(embeddings), len(embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4c8c9f",
   "metadata": {},
   "source": [
    "## **openAI Embedding Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3dec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFium2Loader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "#임베딩 모델 API 호출\n",
    "embeddings_model = OpenAIEmbeddings(model = 'text-embedding-3-small')\n",
    "\n",
    "#PDF 문서 로드\n",
    "# loader = PyPDFium2Loader(r\"G:\\내 드라이브\\문영호\\109 RFP MOH eng.pdf\")\n",
    "# loader = PyPDFium2Loader(r\"G:\\내 드라이브\\문영호\\알파고\\alphago.pdf\")\n",
    "# loader = PyPDFium2Loader(r\"G:\\내 드라이브\\LLM-RAG-LangChain\\대한민국헌법(헌법)(제00010호)(19880225).pdf\")\n",
    "loader = PyPDFium2Loader(\n",
    "    r\"/Users/youngho_moon/Library/CloudStorage/GoogleDrive-anskong@gmail.com/내 드라이브/LLM-RAG-LangChain/대한민국헌법(헌법)(제00010호)(19880225).pdf\"\n",
    ")\n",
    "# PDF파일 로드 및 페이지별로 자르기\n",
    "pages = loader.load()\n",
    "\n",
    "#PDF 문서를 여러 청크로 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_documents(pages)\n",
    "\n",
    "#청크 수 확인\n",
    "print(f\"청크 수: {len(texts)}\")\n",
    "#청크 내용 확인\n",
    "print(\"started printing chunk contents\")\n",
    "for i in range(1,2):   \n",
    "    print(f\"청크 {i+1} 내용\") \n",
    "    print(\"===================================\")\n",
    "    print(texts[i].page_content)\n",
    "    print(texts[i].metadata)\n",
    "    print(texts[i].metadata['page'])\n",
    "    # print(texts[i].metadata['page_label'])\n",
    "print(\"finished printing chunk contents\")\n",
    "\n",
    "#OpenAI 임베딩 모델로 청크들을 임베딩 변환하기\n",
    "embeddings = embeddings_model.embed_documents([i.page_content for i in texts])\n",
    "len(embeddings), len(embeddings[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d9eb64",
   "metadata": {},
   "source": [
    "##### **[문장 유사도]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2dc6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = [\n",
    "        \"안녕하세요\",\n",
    "        \"제 이름은 홍두깨입니다.\",\n",
    "        \"AI 초보자로서 잘 부탁드립니다.\",\n",
    "        \"열심히 배워서 회사의 발전에 이바지할 수 있는 인재로 성장하겠습니다.\",\n",
    "        \"LG CNS 만세 저는 아부쟁이입니다.\"\n",
    "    ]\n",
    "embeddings = embeddings_model.embed_documents(chunk)\n",
    "print(embeddings)\n",
    "\n",
    "# 임베딩 모델 API 호출 - embed_query\n",
    "embedded_query_q1 = embeddings_model.embed_query(\"이 대화에서 언급된 이름은 무엇입니까?\")\n",
    "embedded_query_q2 = embeddings_model.embed_query(\"이 대화에서 언급된 사람의 포부는 무엇입니까?\")\n",
    "embedded_query_q3 = embeddings_model.embed_query(\"이 대화에서 언급된 사람은 아부쟁이일까요 아닐까요?\")\n",
    "embedded_query_a = embeddings_model.embed_query(\"이 대화에서 언급된 이름은 홍길동입니다.\")\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "\n",
    "# 임베딩 간 유사도 함수\n",
    "def cos_sim(A, B):\n",
    "       return dot(A, B)/(norm(A)*norm(B))\n",
    "\n",
    "for i in range(len(embeddings)):\n",
    "    print(chunk[i])\n",
    "    print(cos_sim(embedded_query_q3, embeddings[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df37847a",
   "metadata": {},
   "source": [
    "### **오픈소스 임베딩 모델 활용하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2d29b9",
   "metadata": {},
   "source": [
    "**[jhgan/ko-sroberta-multitask 임베딩 모델 활용]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d8649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sentence-transformers\n",
    "# pip install --upgrade sentence-transformers  ->  필요\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "\n",
    "# 임베딩 간 유사도 함수\n",
    "def cos_sim(A, B):\n",
    "       return dot(A, B)/(norm(A)*norm(B))\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "#HuggingfaceEmbedding 함수로 Open source 임베딩 모델 로드\n",
    "model_name = \"jhgan/ko-sroberta-multitask\"\n",
    "ko_embedding= HuggingFaceEmbeddings(\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "examples = ko_embedding.embed_documents(\n",
    "     [\n",
    "        \"안녕하세요\",\n",
    "        \"제 이름은 홍두깨입니다.\",\n",
    "        \"이름이 무엇인가요?\",\n",
    "        \"랭체인은 유용합니다.\",\n",
    "     ]\n",
    " )\n",
    "\n",
    "embedded_query_q = ko_embedding.embed_query(\"이 대화에서 언급된 이름은 무엇입니까?\")\n",
    "embedded_query_a = ko_embedding.embed_query(\"이 대화에서 언급된 이름은 홍길동입니다.\")\n",
    "\n",
    "print(cos_sim(embedded_query_q, embedded_query_a))\n",
    "print(cos_sim(embedded_query_q, examples[1]))\n",
    "print(cos_sim(embedded_query_q, examples[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e4c4d4",
   "metadata": {},
   "source": [
    "**[BAAI/bge-small-en 임베딩 모델 활용 코드]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67608f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "bge_embedding= HuggingFaceEmbeddings(\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "examples = bge_embedding.embed_documents(\n",
    "     [\n",
    "        \"안녕하세요\",\n",
    "        \"제 이름은 홍두깨입니다.\",\n",
    "        \"이름이 무엇인가요?\",\n",
    "        \"랭체인은 유용합니다.\",\n",
    "     ]\n",
    " )\n",
    "\n",
    "embedded_query_q = bge_embedding.embed_query(\"이 대화에서 언급된 이름은 무엇입니까?\")\n",
    "embedded_query_a = bge_embedding.embed_query(\"이 대화에서 언급된 이름은 홍길동입니다.\")\n",
    "\n",
    "print(cos_sim(embedded_query_q, embedded_query_a))\n",
    "print(cos_sim(embedded_query_q, examples[1]))\n",
    "print(cos_sim(embedded_query_q, examples[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2586ae4f",
   "metadata": {},
   "source": [
    "## **문서 벡터 저장소, Vector Stores**\n",
    "### **Langchain-Chroma 문서 저장 및 유사 문서 검색**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452e27ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "openai_embedding=OpenAIEmbeddings(model = 'text-embedding-3-small')\n",
    "\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - window11 \n",
    "# loader = PyPDFLoader(r\"G:\\내 드라이브\\문영호\\109 RFP MOH eng.pdf\")\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - macOS\n",
    "loader = PyPDFLoader(\n",
    "    r\"/Users/youngho_moon/Library/CloudStorage/GoogleDrive-anskong@gmail.com/내 드라이브/LLM-RAG-LangChain/대한민국헌법(헌법)(제00010호)(19880225).pdf\"\n",
    ")\n",
    "\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "db = Chroma.from_documents(docs, openai_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c931aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"대통령의 임기는?\"\n",
    "#유사 문서 검색\n",
    "docs = db.similarity_search(query)\n",
    "for doc in docs:\n",
    "    print(\"===================================\")\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)\n",
    "    print(doc.metadata['page'])\n",
    "    # print(doc.metadata['page_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f601860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#유사 문서 검색 및 유사도 출력\n",
    "db.similarity_search_with_score(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e85f78",
   "metadata": {},
   "source": [
    "**<span style='color:green'>[벡터DB를 로컬 디스크에 저장하고 로드하기]</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c1f9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Chroma().delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8ac890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - macOS\n",
    "loader = PyPDFLoader(\n",
    "    r\"/Users/youngho_moon/Library/CloudStorage/GoogleDrive-anskong@gmail.com/내 드라이브/LLM-RAG-LangChain/대한민국헌법(헌법)(제00010호)(19880225).pdf\"\n",
    ")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "\n",
    "#HuggingfaceEmbedding 함수로 Open source 임베딩 모델 로드\n",
    "model_name = \"jhgan/ko-sroberta-multitask\"\n",
    "ko_embedding= HuggingFaceEmbeddings(\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "#save to local disk,\n",
    "db2 = Chroma.from_documents(docs, ko_embedding, persist_directory=\"./chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42381e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from disk\n",
    "db3 = Chroma(persist_directory=\"./chroma_db\", embedding_function=ko_embedding)\n",
    "\n",
    "query = \"대통령의 임기는?\"\n",
    "result = db3.similarity_search(query)\n",
    "print(result[0].page_content)\n",
    "\n",
    "# # load from disk\n",
    "# db3 = Chroma(persist_directory=\"./chroma_db\", embedding_function=ko_embedding)\n",
    "\n",
    "# query = \"대통령의 임기는?\"\n",
    "# result = db3.similarity_search(query)\n",
    "# print(result[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffeace1",
   "metadata": {},
   "source": [
    "## **RAG의 핵심, 문서 검색기 Retriever**\n",
    "### **Retriever의 기본형, 벡터DB 기반 Retriever**\n",
    "**<span style='color:yellow'>Chroma 벡터 DB 기반 기본 유사 문서 검색</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aa85ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "#헌법 PDF 파일 로드\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - macOS\n",
    "loader = PyPDFLoader(\n",
    "    r\"/Users/youngho_moon/Library/CloudStorage/GoogleDrive-anskong@gmail.com/내 드라이브/LLM-RAG-LangChain/대한민국헌법(헌법)(제00010호)(19880225).pdf\"\n",
    ")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "#PDF 파일을 500자 청크로 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "#ChromaDB에 청크들을 벡터 임베딩으로 저장(OpenAI 임베딩 모델 활용)\n",
    "db = Chroma.from_documents(docs, OpenAIEmbeddings(model = 'text-embedding-3-small'))\n",
    "\n",
    "#Chroma를 Retriever로 활용\n",
    "retriever = db.as_retriever()\n",
    "retriever.invoke(\"국회의원의 의무\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3ecd68",
   "metadata": {},
   "source": [
    "**(1) 검색 결과 수 및 조정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e84dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#유사 청크 1개만 반환\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 10})\n",
    "retriever.invoke(\"국회의원의 의무\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db2b754",
   "metadata": {},
   "source": [
    "**(2) 검색 방식 변경 - MMR**\n",
    "\n",
    "MMR은 쿼리에 대한 (1) 각 문서의 유사성 점수와 (2) 이미 선택된 문서들과의 다양성점수를 조합하여, 각 문서의 최종 점수를 계산합니다.\n",
    "\n",
    "$\\text{MMR} = \\lambda \\cdot \\text{Sim}(d, Q) - (1 - \\lambda) \\cdot \\max_{d' \\in D'} \\text{Sim}(d, d')$\n",
    "\n",
    "즉 유사 문서 후보군 중 특정 문서가 후보군 내 문서들 간의 유사성은 낮고, 쿼리와의 유사성이 높은 경우 점수가 높습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e58ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "#헌법 PDF 파일 로드\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - macOS\n",
    "loader = PyPDFLoader(\n",
    "    r\"/Users/youngho_moon/Library/CloudStorage/GoogleDrive-anskong@gmail.com/내 드라이브/LLM-RAG-LangChain/대한민국헌법(헌법)(제00010호)(19880225).pdf\"\n",
    ")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "#PDF 파일을 500자 청크로 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "#ChromaDB에 청크들을 벡터 임베딩으로 저장(OpenAI 임베딩 모델 활용)\n",
    "db = Chroma.from_documents(docs, OpenAIEmbeddings(model = 'text-embedding-3-small'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d011ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chroma를 Retriever로 활용\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs = {\"lambda_mult\": 0, \"fetch_k\":10, \"k\":3}\n",
    ")\n",
    "result = retriever.invoke(\"국회의원의 의무\")\n",
    "for idx, value in enumerate(result):\n",
    "  print(f\"{idx+1}번째 유사 문서:\")\n",
    "  print(value.page_content[:100])\n",
    "  print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa09ae9",
   "metadata": {},
   "source": [
    "**<span style='color:yellow'>일반 유사도 검색 방식**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3defda85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chroma를 Retriever로 활용\n",
    "retriever = db.as_retriever(search_kwargs = {\"k\":3})\n",
    "result = retriever.invoke(\"국회의원의 의무\")\n",
    "for idx, value in enumerate(result):\n",
    "  print(f\"{idx+1}번째 유사 문서:\")\n",
    "  print(value.page_content[:100])\n",
    "  print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
