{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "970fbe07",
   "metadata": {},
   "source": [
    "LLM - chatGPT, Anthropic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfd496b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai key values ::: 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\n",
      "anthropic key values ::: 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\n",
      "huggingface_token::: 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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경변수 읽어오기\n",
    "load_dotenv(override=True)  # .env 파일을 덮어쓰기 모드로 읽기\n",
    "\n",
    "# 환경변수 불러오기\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "anthropic_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "huggingface_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "print(f\"openai key values ::: {openai_key}\")  # 테스트용 (실제 서비스에서는 print 금지)\n",
    "print(f\"anthropic key values ::: {anthropic_key}\")  # 테스트용 (실제 서비스에서는 print 금지)\n",
    "print(f\"huggingface_token::: {huggingface_token}\")  # 테스트용 (실제 서비스에서는 print 금지)\n",
    "#...ddd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "716129a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anthropic key values ::: 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\n",
      "client values <class 'anthropic.Anthropic'> ::: <anthropic.Anthropic object at 0x000001D9343E74D0>\n",
      "[TextBlock(citations=None, text=\"Anthropic AI는 미국 샌프란시스코에 본사를 둔 인공지능 연구 기업입니다. 2021년 OpenAI, Google Brain 등에서 근무했던 연구원들이 설립했죠. Anthropic은 '구성적 AI(constitutinal AI)'라는 개념을 제시하며, 안전하고 윤리적인 AI 시스템 개발을 목표로 하고 있습니다. \\n\\n구성적 AI는 AI가 스스로 윤리 원칙과 행동 규범을 내재화하도록 학습시키는 방법론입니다. 이를 통해 AI가 인간의 가치관을 존중하고 해로운 행동을 스스로 자제하도록 유도하는 거죠. Anthropic은 이런 접근 방식으로 AI의 안전성과 신뢰성을 높이고자 합니다.\\n\\nAnthropic이 개발 중인 대표적인 AI로는 대화형 AI 모델인 Claude가 있습니다. 저 역시 Claude의 한 버전이라고 할 수 있죠. 아직 베타 버전이지만, 자연스러운 대화와 다양한 작업 수행 능력을 갖추고 있다는 평가를 받고 있습니다. \\n\\n아직 스타트업 단계이지만 Anthropic은 혁신적인 아이디어와 뛰어난 연구진을 갖춘 유망한 AI 기업으로 꼽히고 있습니다. 앞으로가 더욱 기대되는 곳이라고 할 수 있겠네요.\", type='text')]\n"
     ]
    }
   ],
   "source": [
    "import anthropic\n",
    "import httpx    \n",
    "\n",
    "\n",
    "\n",
    "print(f\"anthropic key values ::: {anthropic_key}\")\n",
    "\n",
    "client = anthropic.Anthropic(api_key=anthropic_key)\n",
    "\n",
    "httpx.Client(verify=False)\n",
    "\n",
    "client._client._transport._pool._ssl_context.check_hostname = False\n",
    "client._client._transport._pool._ssl_context.verify_mode = 0  # ssl.CERT_NONE\n",
    "\n",
    "print(\"client values {} ::: {}\".format(type(client), client) ) # 테스트용 (실제 서비스에서는 print 금지)\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=\"claude-3-opus-20240229\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Anthropic AI 소개해줘\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a413a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model_name = 'gpt-4o',\n",
    "    openai_api_key=openai_key\n",
    ")\n",
    "response = chat.invoke(\"너를 소개해줘\")\n",
    "\n",
    "print(response.content)  # 테스트용 (실제 서비스에서는 print 금지)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72b62b1",
   "metadata": {},
   "source": [
    "# **Document Loader**\n",
    "## ***<span style=\"color:yellow\">PDF Loader</span>***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea700c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyPDF 설치\n",
    "# !pip install -q pypdf\n",
    "# G:\\내 드라이브\\문영호\\109 RFP MOH eng.pdf\n",
    "\n",
    "#PyPDFLoader 불러오기\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - window11 \n",
    "# loader = PyPDFLoader(r\"G:\\내 드라이브\\문영호\\109 RFP MOH eng.pdf\")\n",
    "loader = PyPDFLoader(\n",
    "    r\"G:\\내 드라이브\\LLM-RAG-LangChain\\대한민국헌법(헌법)(제00010호)(19880225).pdf\"\n",
    ")\n",
    "\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - macOS\n",
    "# loader = PyPDFLoader(\n",
    "#     r\"/Users/youngho_moon/Library/CloudStorage/GoogleDrive-anskong@gmail.com/내 드라이브/LLM-RAG-LangChain/대한민국헌법(헌법)(제00010호)(19880225).pdf\"\n",
    "# )\n",
    "\n",
    "# PDF파일 로드 및 페이지별로 자르기\n",
    "pages = loader.load_and_split()\n",
    "print(f\"페이지 수: {len(pages)}\")\n",
    "# print(pages[0].page_content)\n",
    "\n",
    "for i in range(5):   \n",
    "    print(f\"페이지 {i+1} 내용\") \n",
    "    print(\"===================================\")\n",
    "    print(pages[i].page_content)\n",
    "    print(pages[i].metadata)\n",
    "    print(pages[i].metadata['page'])\n",
    "    print(pages[i].metadata['page_label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422de17c",
   "metadata": {},
   "source": [
    "# **Text Splitter**\n",
    "\n",
    "<!-- **굵게 (bold)**  \n",
    "*기울임 (italic)*  \n",
    "***굵고 기울임*** -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127676bf",
   "metadata": {},
   "source": [
    "# ***<sapn style=\"color:green\">Text Embbeding</span>***\n",
    "<!-- ## ***글자 크기 조정 2***\n",
    "###  **글자 크기 조정 3** -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409985e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(model = 'text-embedding-3-small')\n",
    "embeddings = embeddings_model.embed_documents(\n",
    "    [\n",
    "        \"Hi there!\",\n",
    "        \"Oh, hello!\",\n",
    "        \"What's your name?\",\n",
    "        \"My friends call me World\",\n",
    "        \"Hello World!\"\n",
    "    ]\n",
    ")\n",
    "len(embeddings), len(embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4c8c9f",
   "metadata": {},
   "source": [
    "## **openAI Embedding Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3dec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFium2Loader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "#임베딩 모델 API 호출\n",
    "embeddings_model = OpenAIEmbeddings(model = 'text-embedding-3-small')\n",
    "\n",
    "#PDF 문서 로드\n",
    "# loader = PyPDFium2Loader(r\"G:\\내 드라이브\\문영호\\109 RFP MOH eng.pdf\")\n",
    "# loader = PyPDFium2Loader(r\"G:\\내 드라이브\\문영호\\알파고\\alphago.pdf\")\n",
    "# loader = PyPDFium2Loader(r\"G:\\내 드라이브\\LLM-RAG-LangChain\\대한민국헌법(헌법)(제00010호)(19880225).pdf\")\n",
    "loader = PyPDFium2Loader(\n",
    "    r\"/Users/youngho_moon/Library/CloudStorage/GoogleDrive-anskong@gmail.com/내 드라이브/LLM-RAG-LangChain/대한민국헌법(헌법)(제00010호)(19880225).pdf\"\n",
    ")\n",
    "# PDF파일 로드 및 페이지별로 자르기\n",
    "pages = loader.load()\n",
    "\n",
    "#PDF 문서를 여러 청크로 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_documents(pages)\n",
    "\n",
    "#청크 수 확인\n",
    "print(f\"청크 수: {len(texts)}\")\n",
    "#청크 내용 확인\n",
    "print(\"started printing chunk contents\")\n",
    "for i in range(1,2):   \n",
    "    print(f\"청크 {i+1} 내용\") \n",
    "    print(\"===================================\")\n",
    "    print(texts[i].page_content)\n",
    "    print(texts[i].metadata)\n",
    "    print(texts[i].metadata['page'])\n",
    "    # print(texts[i].metadata['page_label'])\n",
    "print(\"finished printing chunk contents\")\n",
    "\n",
    "#OpenAI 임베딩 모델로 청크들을 임베딩 변환하기\n",
    "embeddings = embeddings_model.embed_documents([i.page_content for i in texts])\n",
    "len(embeddings), len(embeddings[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d9eb64",
   "metadata": {},
   "source": [
    "##### **[문장 유사도]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2dc6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = [\n",
    "        \"안녕하세요\",\n",
    "        \"제 이름은 홍두깨입니다.\",\n",
    "        \"AI 초보자로서 잘 부탁드립니다.\",\n",
    "        \"열심히 배워서 회사의 발전에 이바지할 수 있는 인재로 성장하겠습니다.\",\n",
    "        \"LG CNS 만세 저는 아부쟁이입니다.\"\n",
    "    ]\n",
    "embeddings = embeddings_model.embed_documents(chunk)\n",
    "print(embeddings)\n",
    "\n",
    "# 임베딩 모델 API 호출 - embed_query\n",
    "embedded_query_q1 = embeddings_model.embed_query(\"이 대화에서 언급된 이름은 무엇입니까?\")\n",
    "embedded_query_q2 = embeddings_model.embed_query(\"이 대화에서 언급된 사람의 포부는 무엇입니까?\")\n",
    "embedded_query_q3 = embeddings_model.embed_query(\"이 대화에서 언급된 사람은 아부쟁이일까요 아닐까요?\")\n",
    "embedded_query_a = embeddings_model.embed_query(\"이 대화에서 언급된 이름은 홍길동입니다.\")\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "\n",
    "# 임베딩 간 유사도 함수\n",
    "def cos_sim(A, B):\n",
    "       return dot(A, B)/(norm(A)*norm(B))\n",
    "\n",
    "for i in range(len(embeddings)):\n",
    "    print(chunk[i])\n",
    "    print(cos_sim(embedded_query_q3, embeddings[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df37847a",
   "metadata": {},
   "source": [
    "### **오픈소스 임베딩 모델 활용하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2d29b9",
   "metadata": {},
   "source": [
    "**[jhgan/ko-sroberta-multitask 임베딩 모델 활용]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d8649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sentence-transformers\n",
    "# pip install --upgrade sentence-transformers  ->  필요\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "\n",
    "# 임베딩 간 유사도 함수\n",
    "def cos_sim(A, B):\n",
    "       return dot(A, B)/(norm(A)*norm(B))\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "#HuggingfaceEmbedding 함수로 Open source 임베딩 모델 로드\n",
    "model_name = \"jhgan/ko-sroberta-multitask\"\n",
    "ko_embedding= HuggingFaceEmbeddings(\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "examples = ko_embedding.embed_documents(\n",
    "     [\n",
    "        \"안녕하세요\",\n",
    "        \"제 이름은 홍두깨입니다.\",\n",
    "        \"이름이 무엇인가요?\",\n",
    "        \"랭체인은 유용합니다.\",\n",
    "     ]\n",
    " )\n",
    "\n",
    "embedded_query_q = ko_embedding.embed_query(\"이 대화에서 언급된 이름은 무엇입니까?\")\n",
    "embedded_query_a = ko_embedding.embed_query(\"이 대화에서 언급된 이름은 홍길동입니다.\")\n",
    "\n",
    "print(cos_sim(embedded_query_q, embedded_query_a))\n",
    "print(cos_sim(embedded_query_q, examples[1]))\n",
    "print(cos_sim(embedded_query_q, examples[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e4c4d4",
   "metadata": {},
   "source": [
    "**[BAAI/bge-small-en 임베딩 모델 활용 코드]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67608f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "bge_embedding= HuggingFaceEmbeddings(\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "examples = bge_embedding.embed_documents(\n",
    "     [\n",
    "        \"안녕하세요\",\n",
    "        \"제 이름은 홍두깨입니다.\",\n",
    "        \"이름이 무엇인가요?\",\n",
    "        \"랭체인은 유용합니다.\",\n",
    "     ]\n",
    " )\n",
    "\n",
    "embedded_query_q = bge_embedding.embed_query(\"이 대화에서 언급된 이름은 무엇입니까?\")\n",
    "embedded_query_a = bge_embedding.embed_query(\"이 대화에서 언급된 이름은 홍길동입니다.\")\n",
    "\n",
    "print(cos_sim(embedded_query_q, embedded_query_a))\n",
    "print(cos_sim(embedded_query_q, examples[1]))\n",
    "print(cos_sim(embedded_query_q, examples[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2586ae4f",
   "metadata": {},
   "source": [
    "## **문서 벡터 저장소, Vector Stores**\n",
    "### **Langchain-Chroma 문서 저장 및 유사 문서 검색**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452e27ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "openai_embedding=OpenAIEmbeddings(model = 'text-embedding-3-small')\n",
    "\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - window11 \n",
    "# loader = PyPDFLoader(r\"G:\\내 드라이브\\문영호\\109 RFP MOH eng.pdf\")\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - macOS\n",
    "loader = PyPDFLoader(\n",
    "    r\"/Users/youngho_moon/Library/CloudStorage/GoogleDrive-anskong@gmail.com/내 드라이브/LLM-RAG-LangChain/대한민국헌법(헌법)(제00010호)(19880225).pdf\"\n",
    ")\n",
    "\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "db = Chroma.from_documents(docs, openai_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c931aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"대통령의 임기는?\"\n",
    "#유사 문서 검색\n",
    "docs = db.similarity_search(query)\n",
    "for doc in docs:\n",
    "    print(\"===================================\")\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)\n",
    "    print(doc.metadata['page'])\n",
    "    # print(doc.metadata['page_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f601860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#유사 문서 검색 및 유사도 출력\n",
    "db.similarity_search_with_score(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e85f78",
   "metadata": {},
   "source": [
    "**<span style='color:green'>[벡터DB를 로컬 디스크에 저장하고 로드하기]</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c1f9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Chroma().delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8ac890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - macOS\n",
    "loader = PyPDFLoader(\n",
    "    r\"/Users/youngho_moon/Library/CloudStorage/GoogleDrive-anskong@gmail.com/내 드라이브/LLM-RAG-LangChain/대한민국헌법(헌법)(제00010호)(19880225).pdf\"\n",
    ")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "\n",
    "#HuggingfaceEmbedding 함수로 Open source 임베딩 모델 로드\n",
    "model_name = \"jhgan/ko-sroberta-multitask\"\n",
    "ko_embedding= HuggingFaceEmbeddings(\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "#save to local disk,\n",
    "db2 = Chroma.from_documents(docs, ko_embedding, persist_directory=\"./chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42381e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from disk\n",
    "db3 = Chroma(persist_directory=\"./chroma_db\", embedding_function=ko_embedding)\n",
    "\n",
    "query = \"대통령의 임기는?\"\n",
    "result = db3.similarity_search(query)\n",
    "print(result[0].page_content)\n",
    "\n",
    "# # load from disk\n",
    "# db3 = Chroma(persist_directory=\"./chroma_db\", embedding_function=ko_embedding)\n",
    "\n",
    "# query = \"대통령의 임기는?\"\n",
    "# result = db3.similarity_search(query)\n",
    "# print(result[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffeace1",
   "metadata": {},
   "source": [
    "## **RAG의 핵심, 문서 검색기 Retriever**\n",
    "### **Retriever의 기본형, 벡터DB 기반 Retriever**\n",
    "**<span style='color:yellow'>Chroma 벡터 DB 기반 기본 유사 문서 검색</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aa85ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "#헌법 PDF 파일 로드\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - macOS\n",
    "loader = PyPDFLoader(\n",
    "    r\"/Users/youngho_moon/Library/CloudStorage/GoogleDrive-anskong@gmail.com/내 드라이브/LLM-RAG-LangChain/대한민국헌법(헌법)(제00010호)(19880225).pdf\"\n",
    ")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "#PDF 파일을 500자 청크로 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "#ChromaDB에 청크들을 벡터 임베딩으로 저장(OpenAI 임베딩 모델 활용)\n",
    "db = Chroma.from_documents(docs, OpenAIEmbeddings(model = 'text-embedding-3-small'))\n",
    "\n",
    "#Chroma를 Retriever로 활용\n",
    "retriever = db.as_retriever()\n",
    "retriever.invoke(\"국회의원의 의무\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3ecd68",
   "metadata": {},
   "source": [
    "**(1) 검색 결과 수 및 조정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e84dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#유사 청크 1개만 반환\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 10})\n",
    "retriever.invoke(\"국회의원의 의무\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db2b754",
   "metadata": {},
   "source": [
    "**(2) 검색 방식 변경 - MMR**\n",
    "\n",
    "MMR은 쿼리에 대한 (1) 각 문서의 유사성 점수와 (2) 이미 선택된 문서들과의 다양성점수를 조합하여, 각 문서의 최종 점수를 계산합니다.\n",
    "\n",
    "$\\text{MMR} = \\lambda \\cdot \\text{Sim}(d, Q) - (1 - \\lambda) \\cdot \\max_{d' \\in D'} \\text{Sim}(d, d')$\n",
    "\n",
    "즉 유사 문서 후보군 중 특정 문서가 후보군 내 문서들 간의 유사성은 낮고, 쿼리와의 유사성이 높은 경우 점수가 높습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e58ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "#헌법 PDF 파일 로드\n",
    "# PDF파일 불러올 객체 PyPDFLoader 선언 - macOS\n",
    "loader = PyPDFLoader(\n",
    "    r\"/Users/youngho_moon/Library/CloudStorage/GoogleDrive-anskong@gmail.com/내 드라이브/LLM-RAG-LangChain/대한민국헌법(헌법)(제00010호)(19880225).pdf\"\n",
    ")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "#PDF 파일을 500자 청크로 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "#ChromaDB에 청크들을 벡터 임베딩으로 저장(OpenAI 임베딩 모델 활용)\n",
    "db = Chroma.from_documents(docs, OpenAIEmbeddings(model = 'text-embedding-3-small'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d011ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chroma를 Retriever로 활용\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs = {\"lambda_mult\": 0, \"fetch_k\":10, \"k\":3}\n",
    ")\n",
    "result = retriever.invoke(\"국회의원의 의무\")\n",
    "for idx, value in enumerate(result):\n",
    "  print(f\"{idx+1}번째 유사 문서:\")\n",
    "  print(value.page_content[:100])\n",
    "  print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa09ae9",
   "metadata": {},
   "source": [
    "**<span style='color:yellow'>일반 유사도 검색 방식**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3defda85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chroma를 Retriever로 활용\n",
    "retriever = db.as_retriever(search_kwargs = {\"k\":3})\n",
    "result = retriever.invoke(\"국회의원의 의무\")\n",
    "for idx, value in enumerate(result):\n",
    "  print(f\"{idx+1}번째 유사 문서:\")\n",
    "  print(value.page_content[:100])\n",
    "  print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
